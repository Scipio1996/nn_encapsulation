Experiment: resnet_shape
------------ Train and Test Options -----------------
C_form: l2
base_save_folder: result/paper
batch_size_test: 128
batch_size_train: 128
beta1: 0.9
dataset: cifar10
debug_mode: False
depth: 14
device_id: [1]
draw_hist: False
encapsulate_G: False
experiment_name: resnet_shape
file_name: result/paper/resnet_shape/opt_train_val_START_epoch_0_END_600.txt
gamma: 0.1
less_data_aug: True
loss_fac: 1.0
loss_form: margin
lr: 0.0001
manual_seed: -1
max_epoch: 600
measure_time: False
momentum: 0.9
multi_crop_test: False
net_config: resnet_same_shape
no_bp_P_L: False
no_visdom: False
non_target_j: False
num_workers: 2
optim: adam
ot_loss_fac: 1.0
phase: train_val
port_id: 8000
random_seed: 3366
remove_bias: False
s35: False
save_epoch: 25
save_folder: result/paper/resnet_shape
schedule: [200, 300, 400]
show_freq: 100
show_test_after_epoch: 100
skip_critic: False
use_cuda: True
weight_decay: 0.0005
withCapRoute: False
------------------ End --------------------
EncapNet (
  (module0): Sequential (
    (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), weights=((32, 3, 3, 3), (32,)), parameters=896
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True), weights=((32,), (32,)), parameters=64
    (2): ReLU(inplace), weights=(), parameters=0
  ), weights=((32, 3, 3, 3), (32,), (32,), (32,)), parameters=960
  (module1): Sequential (
    (0): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), weights=((64, 32, 3, 3), (64,)), parameters=18496
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True), weights=((64,), (64,)), parameters=128
    (2): ReLU(inplace), weights=(), parameters=0
  ), weights=((64, 32, 3, 3), (64,), (64,), (64,)), parameters=18624
  (module2): Sequential (
    (0): Conv2d (64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), weights=((128, 64, 3, 3), (128,)), parameters=73856
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True), weights=((128,), (128,)), parameters=256
    (2): ReLU(inplace), weights=(), parameters=0
  ), weights=((128, 64, 3, 3), (128,), (128,), (128,)), parameters=74112
  (module3): Sequential (
    (0): Conv2d (128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), weights=((256, 128, 3, 3), (256,)), parameters=295168
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True), weights=((256,), (256,)), parameters=512
    (2): ReLU(inplace), weights=(), parameters=0
  ), weights=((256, 128, 3, 3), (256,), (256,), (256,)), parameters=295680
  (module4): Sequential (
    (0): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), weights=((512, 256, 3, 3), (512,)), parameters=1180160
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True), weights=((512,), (512,)), parameters=1024
    (2): ReLU(inplace), weights=(), parameters=0
    (3): AvgPool2d(kernel_size=8, stride=8, padding=0, ceil_mode=False, count_include_pad=True), weights=(), parameters=0
  ), weights=((512, 256, 3, 3), (512,), (512,), (512,)), parameters=1181184
  (final_cls): Linear(in_features=512, out_features=10), weights=((10, 512), (10,)), parameters=5130
)
Total param num # 6.010780 Mb

init learning rate 0.0001000000 at iter 0

[resnet_shape]	epoch/iter [0/600][0/391] ||	Loss: 4.4762, Top1_err: 92.1875, Top5_err: 46.8750 ||	Data/batch time: 0.0569/0.8120
[resnet_shape]	epoch/iter [0/600][100/391] ||	Loss: 0.9478, Top1_err: 70.8075, Top5_err: 19.1136 ||	Data/batch time: 0.0008/0.0329
[resnet_shape]	epoch/iter [0/600][200/391] ||	Loss: 0.6815, Top1_err: 64.0547, Top5_err: 14.5484 ||	Data/batch time: 0.0005/0.0290
[resnet_shape]	epoch/iter [0/600][300/391] ||	Loss: 0.5799, Top1_err: 60.4573, Top5_err: 12.3962 ||	Data/batch time: 0.0004/0.0277
[resnet_shape]	epoch/iter [0/600][390/391] ||	Loss: 0.5289, Top1_err: 58.1640, Top5_err: 11.2480 ||	Data/batch time: 0.0004/0.0276
Summary	epoch/iter [0/600] ||	TRAIN, Top1_err: 58.1640, Top5_err: 11.2480 ||	TEST, Top1_err: 100.0000, Top5_err: 100.0000 ||

model saved at result/paper/resnet_shape/epoch_1.pth
[resnet_shape]	epoch/iter [1/600][0/391] ||	Loss: 0.3403, Top1_err: 48.4375, Top5_err: 7.0312 ||	Data/batch time: 0.0601/0.0791
[resnet_shape]	epoch/iter [1/600][100/391] ||	Loss: 0.3402, Top1_err: 47.1071, Top5_err: 6.6058 ||	Data/batch time: 0.0008/0.0258
[resnet_shape]	epoch/iter [1/600][200/391] ||	Loss: 0.3351, Top1_err: 46.5330, Top5_err: 6.2189 ||	Data/batch time: 0.0005/0.0255
[resnet_shape]	epoch/iter [1/600][300/391] ||	Loss: 0.3314, Top1_err: 45.9017, Top5_err: 6.0138 ||	Data/batch time: 0.0004/0.0254
[resnet_shape]	epoch/iter [1/600][390/391] ||	Loss: 0.3279, Top1_err: 45.4080, Top5_err: 5.8940 ||	Data/batch time: 0.0004/0.0254
Summary	epoch/iter [1/600] ||	TRAIN, Top1_err: 45.4080, Top5_err: 5.8940 ||	TEST, Top1_err: 100.0000, Top5_err: 100.0000 ||

[resnet_shape]	epoch/iter [2/600][0/391] ||	Loss: 0.3071, Top1_err: 39.0625, Top5_err: 6.2500 ||	Data/batch time: 0.0579/0.0704
[resnet_shape]	epoch/iter [2/600][100/391] ||	Loss: 0.3059, Top1_err: 41.8162, Top5_err: 4.7184 ||	Data/batch time: 0.0008/0.0256
[resnet_shape]	epoch/iter [2/600][200/391] ||	Loss: 0.3019, Top1_err: 41.0681, Top5_err: 4.7691 ||	Data/batch time: 0.0005/0.0255
[resnet_shape]	epoch/iter [2/600][300/391] ||	Loss: 0.2984, Top1_err: 40.3888, Top5_err: 4.6096 ||	Data/batch time: 0.0004/0.0258
[resnet_shape]	epoch/iter [2/600][390/391] ||	Loss: 0.2971, Top1_err: 40.2240, Top5_err: 4.5460 ||	Data/batch time: 0.0004/0.0262
Summary	epoch/iter [2/600] ||	TRAIN, Top1_err: 40.2240, Top5_err: 4.5460 ||	TEST, Top1_err: 100.0000, Top5_err: 100.0000 ||

[resnet_shape]	epoch/iter [3/600][0/391] ||	Loss: 0.2843, Top1_err: 36.7188, Top5_err: 3.1250 ||	Data/batch time: 0.0585/0.0721
[resnet_shape]	epoch/iter [3/600][100/391] ||	Loss: 0.2793, Top1_err: 37.3762, Top5_err: 3.9604 ||	Data/batch time: 0.0008/0.0285
[resnet_shape]	epoch/iter [3/600][200/391] ||	Loss: 0.2773, Top1_err: 37.0336, Top5_err: 3.8946 ||	Data/batch time: 0.0005/0.0281
[resnet_shape]	epoch/iter [3/600][300/391] ||	Loss: 0.2765, Top1_err: 36.9342, Top5_err: 3.8310 ||	Data/batch time: 0.0004/0.0280
[resnet_shape]	epoch/iter [3/600][390/391] ||	Loss: 0.2749, Top1_err: 36.7000, Top5_err: 3.7720 ||	Data/batch time: 0.0004/0.0280
Summary	epoch/iter [3/600] ||	TRAIN, Top1_err: 36.7000, Top5_err: 3.7720 ||	TEST, Top1_err: 100.0000, Top5_err: 100.0000 ||

[resnet_shape]	epoch/iter [4/600][0/391] ||	Loss: 0.2376, Top1_err: 32.0312, Top5_err: 2.3438 ||	Data/batch time: 0.0572/0.0703
[resnet_shape]	epoch/iter [4/600][100/391] ||	Loss: 0.2599, Top1_err: 34.2899, Top5_err: 3.1869 ||	Data/batch time: 0.0008/0.0281
[resnet_shape]	epoch/iter [4/600][200/391] ||	Loss: 0.2582, Top1_err: 33.9475, Top5_err: 3.1367 ||	Data/batch time: 0.0005/0.0280
[resnet_shape]	epoch/iter [4/600][300/391] ||	Loss: 0.2573, Top1_err: 33.8325, Top5_err: 3.1172 ||	Data/batch time: 0.0004/0.0280
[resnet_shape]	epoch/iter [4/600][390/391] ||	Loss: 0.2562, Top1_err: 33.6500, Top5_err: 3.1080 ||	Data/batch time: 0.0004/0.0278
Summary	epoch/iter [4/600] ||	TRAIN, Top1_err: 33.6500, Top5_err: 3.1080 ||	TEST, Top1_err: 100.0000, Top5_err: 100.0000 ||

[resnet_shape]	epoch/iter [5/600][0/391] ||	Loss: 0.2355, Top1_err: 30.4688, Top5_err: 3.1250 ||	Data/batch time: 0.0684/0.0815
[resnet_shape]	epoch/iter [5/600][100/391] ||	Loss: 0.2485, Top1_err: 32.4489, Top5_err: 2.8388 ||	Data/batch time: 0.0009/0.0279
[resnet_shape]	epoch/iter [5/600][200/391] ||	Loss: 0.2467, Top1_err: 32.3383, Top5_err: 2.8141 ||	Data/batch time: 0.0006/0.0279
[resnet_shape]	epoch/iter [5/600][300/391] ||	Loss: 0.2435, Top1_err: 31.7198, Top5_err: 2.6786 ||	Data/batch time: 0.0005/0.0279
[resnet_shape]	epoch/iter [5/600][390/391] ||	Loss: 0.2419, Top1_err: 31.4780, Top5_err: 2.6440 ||	Data/batch time: 0.0004/0.0278
Summary	epoch/iter [5/600] ||	TRAIN, Top1_err: 31.4780, Top5_err: 2.6440 ||	TEST, Top1_err: 100.0000, Top5_err: 100.0000 ||

[resnet_shape]	epoch/iter [6/600][0/391] ||	Loss: 0.1935, Top1_err: 21.0938, Top5_err: 2.3438 ||	Data/batch time: 0.0584/0.0719
[resnet_shape]	epoch/iter [6/600][100/391] ||	Loss: 0.2296, Top1_err: 29.5560, Top5_err: 2.2509 ||	Data/batch time: 0.0008/0.0281
[resnet_shape]	epoch/iter [6/600][200/391] ||	Loss: 0.2299, Top1_err: 29.4698, Top5_err: 2.3049 ||	Data/batch time: 0.0005/0.0281
