Experiment: base_102_v2_long_only_sub
------------ Test Options -----------------
KL_factor: 0.1
KL_manner: 1
add_cap_BN_relu: False
add_cap_dropout: False
b_init: zero
base_save_folder: result
batch_size_test: 128
batch_size_train: 128
beta1: 0.9
bigger_input: False
cap_N: 5
cap_model: v2
comp_cap: False
connect_detail: only_sub
dataset: cifar10
debug_mode: False
depth: 14
device_id: 
draw_hist: False
dropout_p: 0.2
experiment_name: base_102_v2_long_only_sub
fc_manner: default
file_name: result/base_102_v2_long_only_sub/opt_train_val_START_epoch_0_END_600.txt
fix_m: False
gamma: 0.1
less_data_aug: True
loss_form: margin
lr: 0.0001
manual_seed: -1
max_epoch: 600
measure_time: False
momentum: 0.9
multi_crop_test: False
no_visdom: False
non_target_j: False
num_workers: 2
optim: adam
phase: train_val
port_id: 9000
pre_ch_num: 256
primary_cap_num: 32
random_seed: 6986
route_num: 3
s35: True
save_epoch: 25
save_folder: result/base_102_v2_long_only_sub
schedule: [200, 300, 400]
setting: top1
show_freq: 100
show_test_after_epoch: 100
squash_manner: paper
use_KL: False
use_cuda: False
use_instanceBN: False
use_multiple: False
weight_decay: 0.0005
------------------ End --------------------
CapNet (
  (layer1): Sequential (
    (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), weights=((32, 3, 3, 3), (32,)), parameters=896
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True), weights=((32,), (32,)), parameters=64
    (2): ReLU(inplace), weights=(), parameters=0
  ), weights=((32, 3, 3, 3), (32,), (32,), (32,)), parameters=960
  (module1): CapConv2(
    (main_conv): CapConv(
      (sub_layer): Sequential(
        (0): Conv2d (32, 64, kernel_size=(1, 1), stride=(1, 1), groups=32)
      )
      (last_relu): ReLU()
      (last_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
      (last_squash): conv_squash(num_shared=32)
    )
    (sub_conv): Sequential(
      (0): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (1): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (2): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (3): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (4): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
    )
  ), weights=((64, 1, 1, 1), (64,), (64,), (64,), (64, 2, 1, 1), (64,), (64,), (64,), (64, 2, 1, 1), (64,), (64,), (64,), (64, 2, 1, 1), (64,), (64,), (64,), (64, 2, 1, 1), (64,), (64,), (64,), (64, 2, 1, 1), (64,), (64,), (64,)), parameters=1856
  (module2): CapConv2(
    (main_conv): CapConv(
      (sub_layer): Sequential(
        (0): Conv2d (64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)
      )
      (last_relu): ReLU()
      (last_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
      (last_squash): conv_squash(num_shared=32)
    )
    (sub_conv): Sequential(
      (0): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (1): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (2): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (3): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (4): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
    )
  ), weights=((128, 2, 3, 3), (128,), (128,), (128,), (128, 4, 1, 1), (128,), (128,), (128,), (128, 4, 1, 1), (128,), (128,), (128,), (128, 4, 1, 1), (128,), (128,), (128,), (128, 4, 1, 1), (128,), (128,), (128,), (128, 4, 1, 1), (128,), (128,), (128,)), parameters=7168
  (module3): CapConv2(
    (main_conv): CapConv(
      (sub_layer): Sequential(
        (0): Conv2d (128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)
      )
      (last_relu): ReLU()
      (last_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      (last_squash): conv_squash(num_shared=32)
    )
    (sub_conv): Sequential(
      (0): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (1): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (2): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (3): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (4): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
    )
  ), weights=((256, 4, 3, 3), (256,), (256,), (256,), (256, 8, 1, 1), (256,), (256,), (256,), (256, 8, 1, 1), (256,), (256,), (256,), (256, 8, 1, 1), (256,), (256,), (256,), (256, 8, 1, 1), (256,), (256,), (256,), (256, 8, 1, 1), (256,), (256,), (256,)), parameters=24064
  (module4): CapConv2(
    (main_conv): CapConv(
      (sub_layer): Sequential(
        (0): Conv2d (256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)
      )
      (last_relu): ReLU()
      (last_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
      (last_squash): conv_squash(num_shared=32)
    )
    (sub_conv): Sequential(
      (0): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (1): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (2): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (3): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
      (4): CapConv(
        (sub_layer): Sequential(
          (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1), groups=32)
        )
        (last_relu): ReLU()
        (last_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        (last_squash): conv_squash(num_shared=32)
      )
    )
  ), weights=((512, 8, 3, 3), (512,), (512,), (512,), (512, 16, 1, 1), (512,), (512,), (512,), (512, 16, 1, 1), (512,), (512,), (512,), (512, 16, 1, 1), (512,), (512,), (512,), (512, 16, 1, 1), (512,), (512,), (512,), (512, 16, 1, 1), (512,), (512,), (512,)), parameters=87040
  (final_cls): CapFC(in_cap_num=512, out_cap_num=10, cap_dim=16, fc_manner=default), weights=((16, 512, 10),), parameters=81920
)
Total param num # 0.774414 Mb

init learning rate 0.0001000000 at iter 0

[base_102_v2_long_only_sub]	epoch/iter [0/600][0/391] ||	Loss: 0.6176, Top1_err: 93.7500, Top5_err: 52.3438 ||	Data/batch time: 0.0535/11.4721
