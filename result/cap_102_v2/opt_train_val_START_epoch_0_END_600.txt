Experiment: cap_102_v2
------------ Train and Test Options -----------------
base_save_folder: result
batch_size_test: 128
batch_size_train: 128
beta1: 0.9
cap_N: 4
cap_model: v2
connect_detail: all
dataset: cifar10
debug_mode: True
device_id: 0,1
draw_hist: False
experiment_name: cap_102_v2
fc_manner: default
file_name: result/cap_102_v2/opt_train_val_START_epoch_0_END_600.txt
gamma: 0.1
layerwise: False
less_data_aug: True
loss_form: margin
lr: 0.0001
manner: 1
manual_seed: -1
max_epoch: 600
measure_time: False
momentum: 0.9
more_skip: False
multi_crop_test: False
no_visdom: False
non_target_j: False
num_workers: 2
optim: adam
phase: train_val
port_id: 8000
random_seed: 8375
s35: False
save_epoch: 1
save_folder: result/cap_102_v2
schedule: [200, 300, 400]
show_freq: 1
show_test_after_epoch: 0
use_cuda: True
weight_decay: 0.0005
wider: False
------------------ End --------------------
CapNet (
  (module0): Sequential (
    (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), weights=((32, 3, 3, 3), (32,)), parameters=896
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True), weights=((32,), (32,)), parameters=64
    (2): ReLU(inplace), weights=(), parameters=0
  ), weights=((32, 3, 3, 3), (32,), (32,), (32,)), parameters=960
  (module1): CapConv2(
    (main_conv): CapConv(
      (conv_adjust_blob_shape): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (block): Sequential(
        (0): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
      )
      (last_squash): conv_squash(num_shared=32)
    )
    (sub_conv): CapConv(
      (block): Sequential(
        (0): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
        (1): conv_squash(num_shared=32)
        (2): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
        (3): conv_squash(num_shared=32)
        (4): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
        (5): conv_squash(num_shared=32)
        (6): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
      )
      (last_squash): conv_squash(num_shared=32)
    )
  ), weights=((64, 32, 3, 3), (64,), (64, 1, 3, 3), (64,), (64,), (64,), (32, 2, 3, 3), (32,), (64, 32, 3, 3), (64,), (64,), (64,), (64, 2, 1, 1), (64,), (64,), (64,), (32, 2, 3, 3), (32,), (64, 64, 1, 1), (64,), (64,), (64,), (64, 2, 1, 1), (64,), (64,), (64,), (32, 2, 3, 3), (32,), (64, 64, 1, 1), (64,), (64,), (64,), (64, 2, 1, 1), (64,), (64,), (64,), (32, 2, 3, 3), (32,), (64, 64, 1, 1), (64,), (64,), (64,), (64, 2, 1, 1), (64,), (64,), (64,), (32, 2, 3, 3), (32,), (64, 64, 1, 1), (64,), (64,), (64,)), parameters=59360
  (module2): CapConv2(
    (main_conv): CapConv(
      (conv_adjust_blob_shape): Conv2d (64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (block): Sequential(
        (0): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
      )
      (last_squash): conv_squash(num_shared=32)
    )
    (sub_conv): CapConv(
      (block): Sequential(
        (0): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
        (1): conv_squash(num_shared=32)
        (2): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
        (3): conv_squash(num_shared=32)
        (4): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
        (5): conv_squash(num_shared=32)
        (6): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (128, 128, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
      )
      (last_squash): conv_squash(num_shared=32)
    )
  ), weights=((128, 64, 3, 3), (128,), (128, 2, 3, 3), (128,), (128,), (128,), (32, 4, 3, 3), (32,), (128, 64, 3, 3), (128,), (128,), (128,), (128, 4, 1, 1), (128,), (128,), (128,), (32, 4, 3, 3), (32,), (128, 128, 1, 1), (128,), (128,), (128,), (128, 4, 1, 1), (128,), (128,), (128,), (32, 4, 3, 3), (32,), (128, 128, 1, 1), (128,), (128,), (128,), (128, 4, 1, 1), (128,), (128,), (128,), (32, 4, 3, 3), (32,), (128, 128, 1, 1), (128,), (128,), (128,), (128, 4, 1, 1), (128,), (128,), (128,), (32, 4, 3, 3), (32,), (128, 128, 1, 1), (128,), (128,), (128,)), parameters=227232
  (module3): CapConv2(
    (main_conv): CapConv(
      (conv_adjust_blob_shape): Conv2d (128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (block): Sequential(
        (0): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
      )
      (last_squash): conv_squash(num_shared=32)
    )
    (sub_conv): CapConv(
      (block): Sequential(
        (0): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
        (1): conv_squash(num_shared=32)
        (2): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
        (3): conv_squash(num_shared=32)
        (4): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
        (5): conv_squash(num_shared=32)
        (6): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (256, 256, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
      )
      (last_squash): conv_squash(num_shared=32)
    )
  ), weights=((256, 128, 3, 3), (256,), (256, 4, 3, 3), (256,), (256,), (256,), (32, 8, 3, 3), (32,), (256, 128, 3, 3), (256,), (256,), (256,), (256, 8, 1, 1), (256,), (256,), (256,), (32, 8, 3, 3), (32,), (256, 256, 1, 1), (256,), (256,), (256,), (256, 8, 1, 1), (256,), (256,), (256,), (32, 8, 3, 3), (32,), (256, 256, 1, 1), (256,), (256,), (256,), (256, 8, 1, 1), (256,), (256,), (256,), (32, 8, 3, 3), (32,), (256, 256, 1, 1), (256,), (256,), (256,), (256, 8, 1, 1), (256,), (256,), (256,), (32, 8, 3, 3), (32,), (256, 256, 1, 1), (256,), (256,), (256,)), parameters=888992
  (module4): CapConv2(
    (main_conv): CapConv(
      (conv_adjust_blob_shape): Conv2d (256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (block): Sequential(
        (0): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
      )
      (last_squash): conv_squash(num_shared=32)
    )
    (sub_conv): CapConv(
      (block): Sequential(
        (0): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
        (1): conv_squash(num_shared=32)
        (2): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
        (3): conv_squash(num_shared=32)
        (4): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
        (5): conv_squash(num_shared=32)
        (6): capConvRoute1(
          (main_cap): Sequential(
            (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1), groups=32)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
          (main_cap_coeff): Conv2d (512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
          (res_cap): Sequential(
            (0): Conv2d (512, 512, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
            (2): ReLU()
            (3): conv_squash(num_shared=32)
          )
        )
      )
      (last_squash): conv_squash(num_shared=32)
    )
  ), weights=((512, 256, 3, 3), (512,), (512, 8, 3, 3), (512,), (512,), (512,), (32, 16, 3, 3), (32,), (512, 256, 3, 3), (512,), (512,), (512,), (512, 16, 1, 1), (512,), (512,), (512,), (32, 16, 3, 3), (32,), (512, 512, 1, 1), (512,), (512,), (512,), (512, 16, 1, 1), (512,), (512,), (512,), (32, 16, 3, 3), (32,), (512, 512, 1, 1), (512,), (512,), (512,), (512, 16, 1, 1), (512,), (512,), (512,), (32, 16, 3, 3), (32,), (512, 512, 1, 1), (512,), (512,), (512,), (512, 16, 1, 1), (512,), (512,), (512,), (32, 16, 3, 3), (32,), (512, 512, 1, 1), (512,), (512,), (512,)), parameters=3516576
  (final_cls): CapFC(in_cap_num=512, out_cap_num=10, cap_dim=16, fc_manner=default), weights=((16, 512, 10),), parameters=81920
)
Total param num # 18.215332 Mb

init learning rate 0.0001000000 at iter 0

[cap_102_v2]	epoch/iter [0/600][0/391] ||	Loss: 0.6525, Top1_err: 88.2812, Top5_err: 42.1875 ||	Data/batch time: 0.0541/2.3100
[cap_102_v2]	epoch/iter [0/600][1/391] ||	Loss: 0.6465, Top1_err: 89.4531, Top5_err: 45.3125 ||	Data/batch time: 0.0369/1.8170
[cap_102_v2]	epoch/iter [0/600][2/391] ||	Loss: 0.6400, Top1_err: 90.1042, Top5_err: 46.8750 ||	Data/batch time: 0.0307/1.6554
[cap_102_v2]	epoch/iter [0/600][3/391] ||	Loss: 0.6312, Top1_err: 90.2344, Top5_err: 46.8750 ||	Data/batch time: 0.0267/1.5733
[cap_102_v2]	epoch/iter [0/600][4/391] ||	Loss: 0.6231, Top1_err: 90.3125, Top5_err: 47.8125 ||	Data/batch time: 0.0249/1.5262
[cap_102_v2]	epoch/iter [0/600][5/391] ||	Loss: 0.6139, Top1_err: 90.1042, Top5_err: 47.5260 ||	Data/batch time: 0.0245/1.4946
[cap_102_v2]	epoch/iter [0/600][6/391] ||	Loss: 0.6062, Top1_err: 90.1786, Top5_err: 47.9911 ||	Data/batch time: 0.0231/1.4716
[cap_102_v2]	epoch/iter [0/600][7/391] ||	Loss: 0.5984, Top1_err: 89.1602, Top5_err: 48.0469 ||	Data/batch time: 0.0228/1.4591
[cap_102_v2]	epoch/iter [0/600][8/391] ||	Loss: 0.5913, Top1_err: 88.8889, Top5_err: 47.6562 ||	Data/batch time: 0.0225/1.4463
[cap_102_v2]	epoch/iter [0/600][9/391] ||	Loss: 0.5855, Top1_err: 88.9062, Top5_err: 47.9688 ||	Data/batch time: 0.0221/1.4405
[cap_102_v2]	epoch/iter [0/600][10/391] ||	Loss: 0.5802, Top1_err: 89.2756, Top5_err: 47.5852 ||	Data/batch time: 0.0220/1.4315
[cap_102_v2]	epoch/iter [0/600][11/391] ||	Loss: 0.5749, Top1_err: 89.0625, Top5_err: 46.9401 ||	Data/batch time: 0.0220/1.4223
[cap_102_v2]	epoch/iter [0/600][12/391] ||	Loss: 0.5713, Top1_err: 88.9423, Top5_err: 47.0553 ||	Data/batch time: 0.0222/1.4146
[cap_102_v2]	epoch/iter [0/600][13/391] ||	Loss: 0.5685, Top1_err: 88.8951, Top5_err: 46.9866 ||	Data/batch time: 0.0218/1.4081
[cap_102_v2]	epoch/iter [0/600][14/391] ||	Loss: 0.5651, Top1_err: 88.5938, Top5_err: 46.4062 ||	Data/batch time: 0.0217/1.4027
[cap_102_v2]	epoch/iter [0/600][15/391] ||	Loss: 0.5625, Top1_err: 88.3301, Top5_err: 45.9473 ||	Data/batch time: 0.0216/1.3977
[cap_102_v2]	epoch/iter [0/600][16/391] ||	Loss: 0.5609, Top1_err: 88.0515, Top5_err: 45.9099 ||	Data/batch time: 0.0215/1.3938
[cap_102_v2]	epoch/iter [0/600][17/391] ||	Loss: 0.5591, Top1_err: 88.1944, Top5_err: 45.7031 ||	Data/batch time: 0.0215/1.3901
[cap_102_v2]	epoch/iter [0/600][18/391] ||	Loss: 0.5578, Top1_err: 88.1990, Top5_err: 45.3125 ||	Data/batch time: 0.0212/1.3866
[cap_102_v2]	epoch/iter [0/600][19/391] ||	Loss: 0.5568, Top1_err: 88.2422, Top5_err: 45.7422 ||	Data/batch time: 0.0213/1.3836
[cap_102_v2]	epoch/iter [0/600][20/391] ||	Loss: 0.5552, Top1_err: 88.1696, Top5_err: 45.2753 ||	Data/batch time: 0.0213/1.3809
[cap_102_v2]	epoch/iter [0/600][21/391] ||	Loss: 0.5538, Top1_err: 88.0682, Top5_err: 45.1349 ||	Data/batch time: 0.0213/1.3785
[cap_102_v2]	epoch/iter [0/600][22/391] ||	Loss: 0.5527, Top1_err: 87.9076, Top5_err: 45.1766 ||	Data/batch time: 0.0213/1.3763
[cap_102_v2]	epoch/iter [0/600][23/391] ||	Loss: 0.5514, Top1_err: 87.6302, Top5_err: 44.7917 ||	Data/batch time: 0.0211/1.3741
[cap_102_v2]	epoch/iter [0/600][24/391] ||	Loss: 0.5500, Top1_err: 87.5000, Top5_err: 44.4062 ||	Data/batch time: 0.0210/1.3720
[cap_102_v2]	epoch/iter [0/600][25/391] ||	Loss: 0.5491, Top1_err: 87.4399, Top5_err: 44.6514 ||	Data/batch time: 0.0210/1.3701
[cap_102_v2]	epoch/iter [0/600][26/391] ||	Loss: 0.5478, Top1_err: 87.3553, Top5_err: 44.1840 ||	Data/batch time: 0.0209/1.3685
[cap_102_v2]	epoch/iter [0/600][27/391] ||	Loss: 0.5468, Top1_err: 87.1931, Top5_err: 44.1964 ||	Data/batch time: 0.0208/1.3668
[cap_102_v2]	epoch/iter [0/600][28/391] ||	Loss: 0.5458, Top1_err: 87.1498, Top5_err: 43.9925 ||	Data/batch time: 0.0209/1.3654
[cap_102_v2]	epoch/iter [0/600][29/391] ||	Loss: 0.5450, Top1_err: 87.2135, Top5_err: 43.9323 ||	Data/batch time: 0.0208/1.3640
[cap_102_v2]	epoch/iter [0/600][30/391] ||	Loss: 0.5443, Top1_err: 87.1976, Top5_err: 43.9264 ||	Data/batch time: 0.0207/1.3627
[cap_102_v2]	epoch/iter [0/600][31/391] ||	Loss: 0.5435, Top1_err: 87.1826, Top5_err: 43.7744 ||	Data/batch time: 0.0207/1.3617
[cap_102_v2]	epoch/iter [0/600][32/391] ||	Loss: 0.5428, Top1_err: 87.1686, Top5_err: 43.9157 ||	Data/batch time: 0.0207/1.3607
[cap_102_v2]	epoch/iter [0/600][33/391] ||	Loss: 0.5421, Top1_err: 87.0175, Top5_err: 43.9798 ||	Data/batch time: 0.0207/1.3604
[cap_102_v2]	epoch/iter [0/600][34/391] ||	Loss: 0.5413, Top1_err: 86.9196, Top5_err: 43.8616 ||	Data/batch time: 0.0206/1.3601
